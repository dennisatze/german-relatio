{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German relatio for narrative extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import split_into_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"../data/bundestag_data.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Some data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD for example data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Apply relatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 354.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# split into sentences\n",
    "split_sentences = split_into_sentences(df, text_col=\"speechContent\",  \n",
    "                                       progress_bar=True, method=\"nltk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document id: 604683\n",
      "Sentence: Frau Präsidentin! \n",
      "\n",
      "Document id: 604683\n",
      "Sentence: Meine werten Kolleginnen und Kollegen! \n",
      "\n",
      "Document id: 604683\n",
      "Sentence: Liebe Kolleginnen und Kollegen von der Union, Sie müssen unter einer\n",
      "gigantischen Verdrängung leiden, wenn Sie hier von\n",
      "„Willkür“, „Geldbeschaffung“ und „Ökozockerei“ reden. \n",
      "\n",
      "Document id: 604683\n",
      "Sentence: ({0})\n",
      "\n",
      "Ich möchte Sie nur an ein paar Fakten erinnern. \n",
      "\n",
      "Document id: 604683\n",
      "Sentence: Ich\n",
      "weiß, es tut manchmal weh, an Fakten erinnert zu werden, aber ich kann es Ihnen nicht ganz ersparen. \n",
      "\n",
      "Document id: 604683\n",
      "Sentence: Ich beziehe mich einmal auf die Jahre seit 1989. Januar 1989:\n",
      "Erhöhung der Mineralölsteuer um 9 Pfennig; \n",
      "\n",
      "({1})\n",
      "\n",
      "Januar 1991: Erhöhung der Mineralölsteuer um\n",
      "3 Pfennig; Juli 1991: Erhöhung der Mineralölsteuer um\n",
      "22 Pfennig;\n",
      "\n",
      "({2})\n",
      "\n",
      "Januar 1994: Erhöhung der Mineralölsteuer um\n",
      "16 Pfennig. \n",
      "\n",
      "Document id: 604683\n",
      "Sentence: ({3})\n",
      "\n",
      "Das alles war in Ihrer Regierungsverantwortung. \n",
      "\n",
      "Document id: 604683\n",
      "Sentence: Das hat auch nicht dazu geführt - Herr Solms, Sie\n",
      "\n",
      "waren auch daran beteiligt -, dass die Kraftfahrzeugsteuer verringert worden ist, wie Sie das hier wohlfeil fordern. \n",
      "\n",
      "Document id: 604683\n",
      "Sentence: ({4})\n",
      "\n",
      "Auch die Kraftfahrzeugsteuer ist im gleichen Zeitraum zumindest für Dieselfahrzeuge - um 24 DM pro 100\n",
      "Kubikzentimeter Hubraum gestiegen. \n",
      "\n",
      "Document id: 604683\n",
      "Sentence: ({5})\n",
      "\n",
      "Sie müssen einmal zu den Fakten zurückkehren, liebe\n",
      "Kolleginnen und Kollegen. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Document id: %s' %split_sentences[0][i])\n",
    "    print('Sentence: %s \\n' %split_sentences[1][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'ab', 'aber', 'ach', 'acht', 'achte', 'achten', 'achter', 'achtes', 'ag', 'alle', 'allein', 'allem', 'allen', 'aller', 'allerdings', 'alles', 'allgemeinen', 'als', 'also', 'am', 'an', 'andere', 'anderem', 'anderen', 'andern', 'anders', 'auch', 'auf', 'aus', 'ausser', 'ausserdem', 'außer', 'außerdem', 'bald', 'bei', 'beide', 'beiden', 'beim', 'beispiel', 'bekannt', 'bereits', 'besonders', 'besser', 'besten', 'bin', 'bis', 'bisher', 'bist', 'da', 'dabei', 'dadurch', 'dafür', 'dagegen', 'daher', 'dahin', 'dahinter', 'damals', 'damit', 'danach', 'daneben', 'dank', 'dann', 'daran', 'darauf', 'daraus', 'darf', 'darfst', 'darin', 'darum', 'darunter', 'darüber', 'das', 'dasein', 'daselbst', 'dass', 'dasselbe', 'davon', 'davor', 'dazu', 'dazwischen', 'daß', 'dein', 'deine', 'deinem', 'deiner', 'dem', 'dementsprechend', 'demgegenüber', 'demgemäss', 'demgemäß', 'demselben', 'demzufolge', 'den', 'denen', 'denn', 'denselben', 'der', 'deren', 'derjenige', 'derjenigen', 'dermassen', 'dermaßen', 'derselbe', 'derselben', 'des', 'deshalb', 'desselben', 'dessen', 'deswegen', 'dich', 'die', 'diejenige', 'diejenigen', 'dies', 'diese', 'dieselbe', 'dieselben', 'diesem', 'diesen', 'dieser', 'dieses', 'dir', 'doch', 'dort', 'drei', 'drin', 'dritte', 'dritten', 'dritter', 'drittes', 'du', 'durch', 'durchaus', 'durfte', 'durften', 'dürfen', 'dürft', 'eben', 'ebenso', 'ehrlich', 'eigen', 'eigene', 'eigenen', 'eigener', 'eigenes', 'ein', 'einander', 'eine', 'einem', 'einen', 'einer', 'eines', 'einige', 'einigen', 'einiger', 'einiges', 'einmal', 'einmaleins', 'elf', 'en', 'ende', 'endlich', 'entweder', 'er', 'erst', 'erste', 'ersten', 'erster', 'erstes', 'es', 'etwa', 'etwas', 'euch', 'früher', 'fünf', 'fünfte', 'fünften', 'fünfter', 'fünftes', 'für', 'gab', 'ganz', 'ganze', 'ganzen', 'ganzer', 'ganzes', 'gar', 'gedurft', 'gegen', 'gegenüber', 'gehabt', 'gehen', 'geht', 'gekannt', 'gekonnt', 'gemacht', 'gemocht', 'gemusst', 'genug', 'gerade', 'gern', 'gesagt', 'geschweige', 'gewesen', 'gewollt', 'geworden', 'gibt', 'ging', 'gleich', 'gross', 'grosse', 'grossen', 'grosser', 'grosses', 'groß', 'große', 'großen', 'großer', 'großes', 'gut', 'gute', 'guter', 'gutes', 'habe', 'haben', 'habt', 'hast', 'hat', 'hatte', 'hatten', 'heisst', 'heißt', 'her', 'heute', 'hier', 'hin', 'hinter', 'hoch', 'hätte', 'hätten', 'ich', 'ihm', 'ihn', 'ihnen', 'ihr', 'ihre', 'ihrem', 'ihren', 'ihrer', 'ihres', 'im', 'immer', 'in', 'indem', 'infolgedessen', 'ins', 'irgend', 'ist', 'ja', 'jahr', 'jahre', 'jahren', 'je', 'jede', 'jedem', 'jeden', 'jeder', 'jedermann', 'jedermanns', 'jedoch', 'jemand', 'jemandem', 'jemanden', 'jene', 'jenem', 'jenen', 'jener', 'jenes', 'jetzt', 'kam', 'kann', 'kannst', 'kaum', 'kein', 'keine', 'keinem', 'keinen', 'keiner', 'kleine', 'kleinen', 'kleiner', 'kleines', 'kommen', 'kommt', 'konnte', 'konnten', 'kurz', 'können', 'könnt', 'könnte', 'lang', 'lange', 'leicht', 'leider', 'lieber', 'los', 'machen', 'macht', 'machte', 'mag', 'magst', 'man', 'manche', 'manchem', 'manchen', 'mancher', 'manches', 'mehr', 'mein', 'meine', 'meinem', 'meinen', 'meiner', 'meines', 'mich', 'mir', 'mit', 'mittel', 'mochte', 'mochten', 'morgen', 'muss', 'musst', 'musste', 'mussten', 'muß', 'möchte', 'mögen', 'möglich', 'mögt', 'müssen', 'müsst', 'na', 'nach', 'nachdem', 'nahm', 'natürlich', 'neben', 'nein', 'neue', 'neuen', 'neun', 'neunte', 'neunten', 'neunter', 'neuntes', 'nicht', 'nichts', 'nie', 'niemand', 'niemandem', 'niemanden', 'noch', 'nun', 'nur', 'ob', 'oben', 'oder', 'offen', 'oft', 'ohne', 'recht', 'rechte', 'rechten', 'rechter', 'rechtes', 'richtig', 'rund', 'sagt', 'sagte', 'sah', 'satt', 'schlecht', 'schon', 'sechs', 'sechste', 'sechsten', 'sechster', 'sechstes', 'sehr', 'sei', 'seid', 'seien', 'sein', 'seine', 'seinem', 'seinen', 'seiner', 'seines', 'seit', 'seitdem', 'selbst', 'sich', 'sie', 'sieben', 'siebente', 'siebenten', 'siebenter', 'siebentes', 'siebte', 'siebten', 'siebter', 'siebtes', 'sind', 'so', 'solang', 'solche', 'solchem', 'solchen', 'solcher', 'solches', 'soll', 'sollen', 'sollte', 'sollten', 'sondern', 'sonst', 'sowie', 'später', 'statt', 'tag', 'tage', 'tagen', 'tat', 'teil', 'tel', 'trotzdem', 'tun', 'uhr', 'um', 'und', 'uns', 'unser', 'unsere', 'unserer', 'unter', 'vergangene', 'vergangenen', 'viel', 'viele', 'vielem', 'vielen', 'vielleicht', 'vier', 'vierte', 'vierten', 'vierter', 'viertes', 'vom', 'von', 'vor', 'wahr', 'wann', 'war', 'waren', 'wart', 'warum', 'was', 'wegen', 'weil', 'weit', 'weiter', 'weitere', 'weiteren', 'weiteres', 'welche', 'welchem', 'welchen', 'welcher', 'welches', 'wem', 'wen', 'wenig', 'wenige', 'weniger', 'weniges', 'wenigstens', 'wenn', 'wer', 'werde', 'werden', 'werdet', 'wessen', 'wie', 'wieder', 'will', 'willst', 'wir', 'wird', 'wirklich', 'wirst', 'wo', 'wohl', 'wollen', 'wollt', 'wollte', 'wollten', 'worden', 'wurde', 'wurden', 'während', 'währenddem', 'währenddessen', 'wäre', 'würde', 'würden', 'zehn', 'zehnte', 'zehnten', 'zehnter', 'zehntes', 'zeit', 'zu', 'zuerst', 'zugleich', 'zum', 'zunächst', 'zur', 'zurück', 'zusammen', 'zwanzig', 'zwar', 'zwei', 'zweite', 'zweiten', 'zweiter', 'zweites', 'zwischen', 'á', 'über', 'überhaupt', 'übrigens']\n",
      "<class 'set'>\n"
     ]
    }
   ],
   "source": [
    "# checking stopwords\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "print(sorted(stopwords))\n",
    "print(type(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 of 134\n"
     ]
    }
   ],
   "source": [
    "from utils import sentence_processing\n",
    "sent_res = sentence_processing(split_sentences, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[604683, 1, 'Meine werten Kolleginnen und Kollegen!', [Meine, werten, Kolleginnen]], [604683, 4, 'Ich\\nweiß, es tut manchmal weh, an Fakten erinnert zu werden, aber ich kann es Ihnen nicht ganz ersparen.', [Ich, weiß, tut]], [604683, 5, 'Ich beziehe mich einmal auf die Jahre seit 1989. Januar 1989:\\nErhöhung der Mineralölsteuer um 9 Pfennig; \\n\\n({1})\\n\\nJanuar 1991: Erhöhung der Mineralölsteuer um\\n3 Pfennig; Juli 1991: Erhöhung der Mineralölsteuer um\\n22 Pfennig;\\n\\n({2})\\n\\nJanuar 1994: Erhöhung der Mineralölsteuer um\\n16 Pfennig.', [Ich, beziehe, mich]], [604683, 11, 'Sie sagen, die Wettbewerbsfähigkeit sei gefährdet, wir seien nicht mehr konkurrenzfähig mit unseren Nachbarn.', [Sie, sagen, sei, seien]], [604683, 13, 'Der ADAC zum\\nBeispiel - ich gebe Ihnen einen Anstoß - hat eine Liste\\nder Preise für einen Liter Bleifrei Super herausgegeben,\\nStand 7. Januar dieses Jahres: Niederlande: 2,10 DM;\\nDänemark: 2,10 DM; Frankreich: 2,03 DM; Belgien:\\n1,95 DM; Deutschland: 1,94 DM.', [ADAC, ich, gebe, Ihnen, Anstoß]], [604683, 14, 'Sie sehen, dass viele\\nunserer Nachbarländer höhere Preise haben als wir.', [Sie, sehen, haben]], [604683, 16, 'Ich weiß nicht, wie Sie das\\nbegründen wollen.', [Ich, weiß, nicht, wollen]], [604683, 21, 'Die Preise\\nspiegeln nicht die wahren Kosten wider.', [Preise, spiegeln, nicht, Kosten]], [604683, 26, 'Aber ich brauche gar nicht so weit in die Vergangenheit zu gehen.', [ich, brauche, nicht, gehen]], [604683, 35, 'Nur bei Ihnen\\nscheint diese Einsicht überhaupt nicht vorhanden zu sein.', [Einsicht, scheint, sein]], [604883, 52, 'Sehr geehrter Herr\\nPräsident!', [Herr, geehrter, Präsident]], [604883, 64, 'Schröder leistet\\ndem Missbrauch mancher Eltern Vorschub, die sich ihrer Pflichten entziehen und ihren Kindern den Unterhalt\\nvorenthalten.', [Schröder, leistet, Missbrauch, Vorschub]], [604883, 67, 'Wir begrüßen diese Entscheidung, im bestehenden BAföG-System zu bleiben, auch\\nwenn der Umfang der nun angekündigten Gelder hinter\\nden von Ihnen geweckten Erwartungen zurückbleibt.', [Wir, begrüßen, Entscheidung]], [604883, 82, 'Ich vermisse in Ihrem\\nVorschlag eine soziale Komponente.', [Ich, vermisse, Komponente]], [604883, 86, 'In dieser\\nFrage schlage ich Ihnen, Frau Bulmahn, eine große Koalition von CDU/CSU und SPD vor, damit auch ohne die\\n\\nGrünen die BAföG-Förderung für die sozial Schwächsten verbessert wird.', [ich, schlage, Ihnen]], [604883, 88, 'Das zeigt, dass man mit guten Vorschlägen auch als Oppositionspartei konstruktive Politik für\\ndieses Land machen und auch durchsetzen kann.', [Das, zeigt, machen]], [604885, 95, 'Meine\\nsehr verehrten Damen und Herren!', [Damen, Meine, verehrten]], [604885, 96, 'Ich stelle zunächst\\neinmal fest, dass das, was die Frau Ministerin und die\\nrot-grüne Koalition organisiert haben, ein Kurswechsel\\nist.', [Ich, stelle, ist]], [604885, 115, 'Weder BAföG noch Stipendien, weder Elternbeiträge\\nnoch ererbtes Vermögen spielen eine wesentliche Rolle.', [BAföG, spielen, Rolle]], [604885, 117, 'In Fächern wie Jura und\\nMedizin - das ärgert mich besonders - kann man fast\\nschon von einer akademischen Vererbung sprechen.', [das, ärgert, mich]], [604885, 122, 'Die finanzielle Sicherung der Studierenden kostet\\nGeld, für viele Zeitgenossen zu viel Geld; ich weiß das.', [Sicherung, kostet, Geld]], [604885, 124, 'Dies zeigt auch der Vorschlag von Edelgard\\nBulmahn.', [Vorschlag, zeigt, Dies]]]\n"
     ]
    }
   ],
   "source": [
    "print(sent_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing after extraction\n",
    "\n",
    "doc_ids = []\n",
    "for i in range(len(sent_res)):\n",
    "    doc_ids.append(sent_res[i][0])\n",
    "\n",
    "sent_ids = []\n",
    "for i in range(len(sent_res)):\n",
    "    sent_ids.append(sent_res[i][1])\n",
    "\n",
    "sent_full = []\n",
    "for i in range(len(sent_res)):\n",
    "    sent_full.append(sent_res[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import mine_entities\n",
    "ents_subs = mine_entities(dat_sent[\"subs_processed\"], ent_labels = [\"LOC\", \"ORG\", \"PER\"])\n",
    "ents_obs = mine_entities(dat_sent[\"obs_processed\"], ent_labels = [\"LOC\", \"ORG\", \"PER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_subs = ents_subs.most_common(30)\n",
    "common_obs = ents_obs.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_sent = pd.DataFrame({\"doc_ids\": doc_ids, \"sent_ids\" : sent_ids, \"sent_full\" : sent_full, \"narr_id\": narr_id, \"subs\": narr_subs, \n",
    "                        \"negs\": narr_negs, \"verbs\": narr_verbs, \"objects\": narr_obs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep top n Named Entities\n",
    "\n",
    "common_subs = ents_subs.most_common(30)\n",
    "common_obs = ents_obs.most_common(30)\n",
    "\n",
    "common_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ents_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put counts together\n",
    "all_ents = ents_subs + ents_obs\n",
    "\n",
    "\n",
    "len(ents_subs)\n",
    "len(ents_obs)\n",
    "len(all_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep those with more than 20 mentions (arbitrary number for now)\n",
    "\n",
    "keep_ents = {key: value for key, value in all_ents.items() if value >= 20}\n",
    "len(keep_ents)\n",
    "\n",
    "str(keep_ents.keys)\n",
    "\n",
    "# check whether sub, obj is in top entities\n",
    "dat_sent[\"top_entity_subs\"] = dat_sent['subs_processed'].apply(lambda x: 1 if x in keep_ents else 0)\n",
    "dat_sent[\"top_entity_obs\"] = dat_sent['obs_processed'].apply(lambda x: 1 if x in keep_ents else 0)\n",
    "\n",
    "dat_sent[\"top_entity\"] = dat_sent[\"top_entity_subs\"] + dat_sent[\"top_entity_obs\"]\n",
    "\n",
    "dat_sent.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save checkpoint: mined entities\n",
    "\n",
    "#import pickle\n",
    "\n",
    "#with open('ents_subs.pickle', 'wb') as outputfile:\n",
    "#    pickle.dump(ents_subs, outputfile)\n",
    "\n",
    "#with open('ents_obs.pickle', 'wb') as outputfile:\n",
    "#    pickle.dump(ents_obs, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process roles without named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find roles that are not in top n entities\n",
    "non_ner_dat = dat_sent.loc[dat_sent['top_entity'] < 1]\n",
    "non_ner_subs = dat_sent.loc[dat_sent['top_entity_subs'] < 1]\n",
    "non_ner_obs = dat_sent.loc[dat_sent['top_entity_obs'] < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_top_n = dat_sent.loc[dat_sent['top_entity'] > 0]\n",
    "dat_top_n.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ner_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_sent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning using FastText embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advantages: even out-of-vocab words have representation, also character-level embedding helps with misspelled words. \n",
    "\n",
    "from gensim.models import FastText\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "# load existing model\n",
    "model = load_facebook_model(\"..\\\\03_data\\\\fasttext_model.bin\")\n",
    "\n",
    "\n",
    "# Preprocessing for fasttext embeddings\n",
    "lem_nlp = spacy.load(\"de_core_news_lg\", disable=['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'ner'])\n",
    "\n",
    "\n",
    "# lemmatize\n",
    "sentences = list(map(lambda x: ' '.join([w.lemma_ for w in lem_nlp(x)]), split_sentences[1]))\n",
    "\n",
    "# lowercase\n",
    "sentences = [tok.lower() for tok in sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numbers\n",
    "numbs = str.maketrans(\"\", \"\", string.digits)\n",
    "sentences = [tok.translate(numbs) for tok in sentences]\n",
    "\n",
    "# remove punctuation\n",
    "puncts = str.maketrans(\"\", \"\", string.punctuation)\n",
    "sentences = [tok.translate(puncts) for tok in sentences]\n",
    "\n",
    "# strip whitespace\n",
    "sentences = [tok.strip() for tok in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sentences_tokenized = [tokenizer.tokenize(i) for i in sentences]\n",
    "sentences_tokenized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune training \n",
    "model.build_vocab(sentences_tokenized, update=True)\n",
    "\n",
    "model.epochs\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some code to get logging info\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class callback(CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        # note that gensim fasttext implementation currently has not implemented to get loss \n",
    "        #loss = model.get_latest_training_loss()\n",
    "        #print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "model.train(sentences_tokenized, total_examples=len(sentences_tokenized), epochs=model.epochs, callbacks = [callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get relevant vectors\n",
    "subs_vecs = model.wv[dat_sent[\"subs_processed\"]]\n",
    "obs_vecs = model.wv[dat_sent[\"obs_processed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dic = dict.fromkeys(dat_sent[\"subs_processed\"], subs_vecs)\n",
    "\n",
    "subs_vecs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from utils for clustering\n",
    "from utils import get_vector\n",
    "from utils import get_vectors\n",
    "from utils import train_cluster_model\n",
    "from utils import get_clusters\n",
    "from utils import label_clusters_most_freq\n",
    "from utils import label_clusters_most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_km_training = train_cluster_model(subs_vecs, n_clusters = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_km_training.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label clusters\n",
    "from utils import label_clusters_most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts = test_km_training.predict(subs_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = label_clusters_most_similar(test_km_training, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Final Narratives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all top n narratives: \n",
    "dat_top_n = dat_sent.loc[dat_sent['top_entity'] > 1]\n",
    "dat_top_n.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all entities not in top ner\n",
    "non_ner_subs = dat_sent.loc[dat_sent['top_entity_subs'] < 1][\"subs_processed\"].tolist()\n",
    "non_ner_obs = dat_sent.loc[dat_sent['top_entity_obs'] < 1][\"obs_processed\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ner_roles = non_ner_subs + non_ner_obs\n",
    "non_ner_vecs = model.wv[non_ner_roles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ner_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KMeans clustering for correct vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set n clusters\n",
    "n_clust = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_km_training = train_cluster_model(non_ner_vecs, n_clusters = n_clust, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import label_clusters_most_similar\n",
    "clusts = test_km_training.predict(non_ner_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_ner_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ner_df = pd.DataFrame({\"role\" : non_ner_roles, \"clust_nr\" : clusts.tolist()}, index=range(len(non_ner_vecs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ner_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ner_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_labs = label_clusters_most_similar(test_km_training, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_labs_df = pd.DataFrame.from_dict(clust_labs, orient = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_labs_df.columns = [\"role\", \"vec_value\"]\n",
    "clust_labs_df[\"clust_nr\"] = clust_labs_df.index\n",
    "clust_labs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ner_df = non_ner_df.merge(clust_labs_df, on = 'clust_nr', how = \"left\")\n",
    "non_ner_df.columns = [\"role_unclust\", \"clust_nr\", \"role_clust\", \"vec_value\"]\n",
    "non_ner_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ner_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "non_ner_df = non_ner_df.drop_duplicates(subset = [\"role_unclust\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ner_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_subs = dat_sent.loc[dat_sent['top_entity_subs'] == 1][\"obs_processed\"]\n",
    "top_obs = dat_sent.loc[dat_sent['top_entity_obs'] == 1][\"obs_processed\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into full dat_sent dataframe\n",
    "dat_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### merge clustered subs\n",
    "fin_dat = dat_sent.merge(non_ner_df, left_on=\"subs_processed\", right_on = \"role_unclust\",\n",
    "                         how = \"left\")\n",
    "\n",
    "\n",
    "fin_dat = fin_dat.rename(columns = {\"role_clust\" : \"subs_clust\", \"role_unclust\" : \"subs_unclust\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### merge clustered obs\n",
    "fin_dat = fin_dat.merge(non_ner_df, left_on=\"obs_processed\", right_on = \"role_unclust\",\n",
    "                         how = \"left\")\n",
    "\n",
    "\n",
    "fin_dat = fin_dat.rename(columns = {\"role_clust\" : \"obs_clust\", \"role_unclust\" : \"obs_unclust\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fin_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dat.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output\n",
    "# fin_dat.to_csv(\"final_python_processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
